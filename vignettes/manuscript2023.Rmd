---
title: "manuscript2023"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{manuscript2023}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r init, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


# Overview

This vignette outlines the 2023 manuscript that describes _invivoPKfit_'s use 
in a case study with CvT data from over 200 Chemicals. The main inquiry is to
assess whether we can estimate parameters for one- and two-compartment models
such that the majority of predicted values are "within a factor of two" -- a
common metric used to evaluate physiologically-based pharmacokinetic 
(PBPK) models.


```{r setup}
set.seed(2023)
library(tidyverse, quietly = TRUE)
library(cowplot)
library(RColorBrewer)
devtools::load_all() 

```

To speed up analysis in sections 4 and beyond, we can load an `.rds` file 
that includes the fitted models used in much of the publication.

``` {r file_load, eval=FALSE}
# saveRDS(my_pk, "data-raw/all_cvt_pk_JOINT.rds")
my_pk <- readRDS("data-raw/all_cvt_pk_JOINT.rds")
today <- format(Sys.Date(), "%d%B%Y")

```



# Table of Contents

1. Pulling Data from CvTdb  
  - Minimal `pk` object  
2. Running all possible fitting options  
  - Evaluating fitting options  
  - Head-to-head comparison of pooled vs joint models  
3. Running dose-normalized, log-transformed, joint fits  
4. Analysis Plots  
  - CvTdb replicate variation (Figure 4A & Supp. Figure 2A)  
  - CvTdb replicate variation over ADME-normalized time (Figure 4B)  
  - CvTdb concentration and final time-point distributions (Supp. Figure 2B)  
  - invivoPKfit fit option selection (Supp. Table 1)  
  - invivoPKfit model performance (Supp. Figure 2)  
  - Model performance vs Data variability (Figure 5 and Alternative)  
  - Goodness of fit plots (Figure 6)  
  - Fits that may be improved (Supplementary Figure 3)  
5. Lombardo Analysis  
  - Chemicals included  
  - Comparison of derived TK stats  (Figure 7A)  
  - Histograms for Steady-state Volume of Dist. and Total Clearance (Supplemental Figure 4)
6. Benchmarking invivoPKfit
  - Parallelization speeds up the process of fitting (Supplementary Figure 5)


## Pulling data from CvTdb

See `pulling_iv_oral_cvtdb.Rmd`.

### Minimal PK object

The following chunk shows the column/field mapping from the `cvt` object and
the `pk` object needed for invivoPKfit analysis.
The `cvt` object is data from the CvTdb database that includes chemicals with
oral or intravenous routes of administration and takes measurements from
blood or plasma. The data has been processed and cleaned to facilitate its use
with _invivoPKfit_.

```{r pk_obj_fromSQL, eval=FALSE}

### Minimal PK Object ###----
# Minimum pk object, add options later
# Note that these mappings are now a default mappings, just being verbose here.
minimal_pk <- pk(data = cvt,
                 mapping = ggplot2::aes(
                   Chemical = analyte_dtxsid,
                   Chemical_Name = analyte_name_original,
                   DTXSID = analyte_dtxsid,
                   CASRN = analyte_casrn,
                   Species = species,
                   Reference = document_id,
                   Media = conc_medium_normalized,
                   Route = administration_route_normalized,
                   Dose = dose_level_normalized,
                   Dose.Units = "mg/kg",
                   Subject_ID = subject_id,
                   Series_ID = series_id,
                   Study_ID = study_id,
                   ConcTime_ID = conc_time_id,
                   N_Subjects = n_subjects_in_series,
                   Weight = weight_kg,
                   Weight.Units = "kg",
                   Time = time_hr,
                   Time.Units = "hours",
                   Value = conc,
                   Value.Units = "mg/L",
                   Value_SD = conc_sd_normalized,
                   LOQ = loq
                 ))
```


## Running all possible fitting options

Here we setup the PK object with the various options for fitting and data
transformations. As shown in this vignette, it is possible to setup multiple
distinct options for fitting and data transformation at once prior to processing
and fitting the data.

```{r pooled_fitting_choices, eval=FALSE}
# Types of Choices:
## Dose Normalized
## Log10 transform
## Scale time

# Pooled
my_pk_000p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    # "bobyqa",
    "L-BFGS-B"
  )) +
  scale_conc(dose_norm = FALSE, log10_trans = FALSE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species)) 

my_pk_100p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    # "bobyqa",
    "L-BFGS-B"
  )) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species)) 

my_pk_110p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
  )) +
  scale_conc(dose_norm = TRUE, log10_trans = TRUE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species)) 

my_pk_111p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    # "bobyqa",
    "L-BFGS-B"
  )) +
  scale_conc(dose_norm = TRUE, log10_trans = TRUE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species))

my_pk_010p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
  )) +
  scale_conc(dose_norm = FALSE, log10_trans = TRUE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species)) 

my_pk_011p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
  )) +
  scale_conc(dose_norm = FALSE, log10_trans = TRUE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species)) 

my_pk_001p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
    )) +
  scale_conc(dose_norm = FALSE, log10_trans = FALSE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species)) 

my_pk_101p <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
    )) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species)) 

```


```{r joint_fitting_choices, eval=FALSE}
# Joint
my_pk_000j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    # "bobyqa",
    "L-BFGS-B"
  )) +
  scale_conc(dose_norm = FALSE, log10_trans = FALSE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference)) 

my_pk_100j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    # "bobyqa",
    "L-BFGS-B"
  )) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference)) 

my_pk_110j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
  )) +
  scale_conc(dose_norm = TRUE, log10_trans = TRUE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference)) 

my_pk_111j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    # "bobyqa",
    "L-BFGS-B"
  )) +
  scale_conc(dose_norm = TRUE, log10_trans = TRUE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference))

my_pk_010j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
  )) +
  scale_conc(dose_norm = FALSE, log10_trans = TRUE) +
  # scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference)) 

my_pk_011j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
  )) +
  scale_conc(dose_norm = FALSE, log10_trans = TRUE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference)) 

my_pk_001j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
    )) +
  scale_conc(dose_norm = FALSE, log10_trans = FALSE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference)) 

my_pk_101j <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = FALSE,
                      suppress.messages = TRUE) +
  settings_optimx(method = c(
    "L-BFGS-B",
    "bobyqa"
    )) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  scale_time(new_units = "auto") +
  # stat_model() + 
  stat_error_model(error_group = vars(Chemical, Species, Reference))  
```


### Evaluating fitting options

Here I evaluate the various fitting options by counting the number of fits 
for each model that "won" based on AIC. This is given by the `get_winning_model`
method. Furthermore, I also calculate the root mean squared error (RMSE)
for AUC~inf~ and C~max~ values. The _observed_ values in this calculation are
the results of the non-compartmental analysis. Importantly,
all Chemical, Species, Reference, Route, Media, Dose data groups with
AUC~inf~ values that are non-finite or zero in either
non-compartmental or _invivoPKfit_ analysis are not included in the 
calculation for RMSE (of AUC or C~max~). This is to exclude the "incalculable"
RMSEs such that they won't impact our assessment of each set of options'
_goodness-of-fit_. Lastly, we calculate more detailed statistics such as R^2^
and average fold error for each model, method, and set **data_group** for downstream
analyses.

```{r Evaluation-helpers, eval=FALSE}
# Evaluation

get_choices <- function(obj, PJ = "Pooled") {
  dose_norm <- obj$scales$conc$dose_norm
  log10_norm <- obj$scales$conc$log10_trans
  time_scale <- ifelse(obj$scales$time$new_units == "identity", FALSE, TRUE)
  
  my_choices <- paste0(dose_norm+0,
                       log10_norm+0,
                       time_scale+0,
                       " ", PJ)
  return(my_choices)
}

# Write into package
evaluate_choices <- function(obj, PJ = "Pooled") {
  pk_name <- get_choices(obj, PJ = PJ)
  
  cli::cli_progress_step("Winning Model...")
  # Wide winning model
  suppressMessages({
    winning_model <- get_winning_model(obj = obj) 
    wide_winning_model <- winning_model %>%
      group_by(method, model) %>%
      count() %>%
      pivot_wider(names_from = model, values_from = n) %>%
      mutate(Options = pk_name)
  })
  
  
  cli::cli_progress_step("Cmax and AUC_inf RMSEs...")
  # Cmax and AUC_inf RMSEs
  suppressMessages({
    RMSE_eval <- eval_tkstats(obj = obj) %>%
      mutate(Options = pk_name) %>%
      dplyr::select(Options,
                    Chemical, Species,
                    Route, Media, Reference,
                    method, model,
                    starts_with("Cmax"),
                    starts_with("AUC_")) %>%
      filter(abs(AUC_infinity.nca / AUC_tlast.nca) < 10,
             is.finite(AUC_infinity.nca), is.finite(AUC_infinity.tkstats),
             AUC_infinity.nca > 0, AUC_infinity.tkstats > 0) %>%
      rowwise() %>%
      mutate(SE_Cmax = (Cmax.tkstats - Cmax.nca)^2,
             SE_AUC_inf = (AUC_infinity.tkstats - AUC_infinity.nca)^2) %>%
      filter(!is.na(SE_Cmax), !is.na(SE_AUC_inf)) %>%
      group_by(Options, method) %>%
      summarize(RMSE_Cmax = sqrt(mean(SE_Cmax,
                                      na.rm = FALSE)) %>% signif(digits = 4),
                RMSE_AUC = sqrt(mean(SE_AUC_inf,
                                     na.rm = FALSE)) %>% signif(digits = 4))
  })
  
  
  cli::cli_progress_step("More detailed metrics...")
  # Other metrics (detailed)
  suppressMessages({
    r2_df <- rsq(obj, use_scale_conc = FALSE,
                 use_group = ggplot2::vars(
                   Chemical,
                   Species
                 )) %>%
    inner_join(winning_model)
  myAIC <- AIC(obj) %>%
    inner_join(winning_model)
  fold_errors_all <- fold_errors(obj) %>%
    inner_join(winning_model) %>%
    dplyr::filter(Detect %in% TRUE) %>%
    dplyr::group_by(!!!obj$data_group, model, method) %>%
    dplyr::summarize(avg_FoldErr = mean(Fold_Error, na.rm = TRUE) %>%
                       signif(digits = 4),
                     median_FoldErr = median(Fold_Error, na.rm = TRUE) %>%
                       signif(digits = 4),
                     within_2fold = sum(
                       Fold_Error >= 0.5 & Fold_Error <= 2
                       )/length(Fold_Error) %>%
                       signif(digits = 4))
  
  myRMSE_all <- rmse(obj,
                     rmse_group = vars(Route, Media, Dose),
                     use_scale_conc = FALSE) %>% 
    inner_join(winning_model) %>%
    dplyr::group_by(!!!obj$data_group, model, method) %>%
    dplyr::summarize(avg_MSE = mean(RMSE^2, na.rm = TRUE) %>%
                       signif(digits = 4),
                     median_MSE = median(RMSE^2, na.rm = TRUE) %>%
                       signif(digits = 4))
  
  my_df <- left_join(fold_errors_all, r2_df) %>%
    inner_join(myAIC) %>%
    inner_join(myRMSE_all) %>%
    mutate(Options = pk_name, .before = Chemical)
  
  # Are there models that have lower RMSE than the winning model
  winmodel_conflict <- rmse(obj, use_scale_conc = FALSE,
                            rmse_group =vars(Chemical, Species, Route, Media, Dose, Time)) %>%
    group_by(Chemical, Species, Route, Media, Dose, Time) %>%
    filter(RMSE == min(RMSE)) %>%
    group_by(Chemical, Species) %>%
    count(model) %>%
    filter(n == max(n)) %>%
    inner_join(winning_model %>% rename("winmodel" = "model")) %>%
    filter(!(model == winmodel))
  
  
  full_list <- list(wide_winning_model, RMSE_eval, my_df, winmodel_conflict)
  })
  
  return(full_list)
}
gc()
```

```{r Evaluating choices, eval=FALSE}

### Evaluations-----
{
my_pk_000p <- do_fit(my_pk_000p, n_cores = 14) #%>% evaluate_choices() # Done
my_pk_100p <- do_fit(my_pk_100p, n_cores = 14) #%>% evaluate_choices() # Done
my_pk_111p <- do_fit(my_pk_111p, n_cores = 14) #%>% evaluate_choices() # Done
my_pk_110p <- do_fit(my_pk_110p, n_cores = 14) #%>% evaluate_choices() # Done

my_pk_010p <- do_fit(my_pk_010p, n_cores = 14) %>% evaluate_choices() # Done
my_pk_011p <- do_fit(my_pk_011p, n_cores = 14) %>% evaluate_choices() # Done 
my_pk_001p <- do_fit(my_pk_001p, n_cores = 14) %>% evaluate_choices() # Done
my_pk_101p <- do_fit(my_pk_101p, n_cores = 14) %>% evaluate_choices() # Done
}

{
winning_model_final <- do.call("bind_rows", args = list(
  my_pk_000p[1],
  my_pk_100p[1],
  my_pk_110p[1],
  my_pk_111p[1],
  my_pk_010p[1],
  my_pk_011p[1],
  my_pk_001p[1],
  my_pk_101p[1]
))

rmse_summary <- do.call("bind_rows", args = list(
  my_pk_000p[2],
  my_pk_100p[2],
  my_pk_110p[2],
  my_pk_111p[2],
  my_pk_010p[2],
  my_pk_011p[2],
  my_pk_001p[2],
  my_pk_101p[2]
))

detail_stats <- do.call("bind_rows", args = list(
  my_pk_000p[3],
  my_pk_100p[3],
  my_pk_110p[3],
  my_pk_111p[3],
  my_pk_010p[3],
  my_pk_011p[3],
  my_pk_001p[3],
  my_pk_101p[3]
))

lower_RMSE <- do.call("bind_rows", args = list(
  my_pk_000p[4],
  my_pk_100p[4],
  my_pk_110p[4],
  my_pk_111p[4],
  my_pk_010p[4],
  my_pk_011p[4],
  my_pk_001p[4],
  my_pk_101p[4]
))

}


rm(my_pk_010p, my_pk_011p,my_pk_001p,my_pk_101p,
   my_pk_000p, my_pk_100p,my_pk_110p,my_pk_111p)
gc()

{
my_pk_000j <- do_fit(my_pk_000j, n_cores = 14)# %>% evaluate_choices(PJ = "Joint") # Done
my_pk_100j <- do_fit(my_pk_100j, n_cores = 14)# %>% evaluate_choices(PJ = "Joint") # Done
my_pk_111j <- do_fit(my_pk_111j, n_cores = 14)# %>% evaluate_choices(PJ = "Joint") # Done
my_pk_110j <- do_fit(my_pk_110j, n_cores = 14)# %>% evaluate_choices(PJ = "Joint") # Done

my_pk_010j <- do_fit(my_pk_010j, n_cores = 14) %>% evaluate_choices(PJ = "Joint") # Done
my_pk_011j <- do_fit(my_pk_011j, n_cores = 14) %>% evaluate_choices(PJ = "Joint") # Done
my_pk_001j <- do_fit(my_pk_001j, n_cores = 14) %>% evaluate_choices(PJ = "Joint") # Done
my_pk_101j <- do_fit(my_pk_101j, n_cores = 14) %>% evaluate_choices(PJ = "Joint") # Done
}

{
winning_model_final <- do.call("bind_rows", args = list(
  winning_model_final,
  my_pk_000j[1],
  my_pk_100j[1],
  my_pk_110j[1],
  my_pk_111j[1],
  my_pk_010j[1],
  my_pk_011j[1],
  my_pk_001j[1],
  my_pk_101j[1]
))

rmse_summary <- do.call("bind_rows", args = list(
  rmse_summary,
  my_pk_000j[2],
  my_pk_100j[2],
  my_pk_110j[2],
  my_pk_111j[2],
  my_pk_010j[2],
  my_pk_011j[2],
  my_pk_001j[2],
  my_pk_101j[2]
))

detail_stats <- do.call("bind_rows", args = list(
  detail_stats,
  my_pk_000j[3],
  my_pk_100j[3],
  my_pk_110j[3],
  my_pk_111j[3],
  my_pk_010j[3],
  my_pk_011j[3],
  my_pk_001j[3],
  my_pk_101j[3]
))

lower_RMSE <- do.call("bind_rows", args = list(
  lower_RMSE,
  my_pk_000j[4],
  my_pk_100j[4],
  my_pk_110j[4],
  my_pk_111j[4],
  my_pk_010j[4],
  my_pk_011j[4],
  my_pk_001j[4],
  my_pk_101j[4]
))
}

rm(my_pk_010j, my_pk_011j,my_pk_001j,my_pk_101j,
   my_pk_000j, my_pk_100j, my_pk_110j, my_pk_111j)

gc()

writexl::write_xlsx(x = list(
  Fit_Counts = winning_model_final,
  AUC_and_Cmax_RMSE_summary = rmse_summary,
  Prediction_Evaluations = detail_stats),
  path = paste0(Sys.getenv("FIG_DIR"),
                "Manu_Files/",
                format(Sys.Date(), "%d%B%Y"),
                "_Supp_Table1",
                ".xlsx"))


lower_RMSE %>% count(Chemical, Species) %>% arrange(desc(n))

detail_stats %>%
  filter(Options %in% c("110 Pooled", "111 Joint")) %>%
  ggplot(aes(x = log10(median_MSE), color = Options)) +
  geom_freqpoly() +
  facet_grid(rows = vars(method)) +
  theme_bw()


```


## Head-to-head comparison of pooled vs joint models

Now I need to go back and re-analyze the data only for 100, 101, and 000
Pooled and Joint, L-BFGS-B only. I need to filter the cvt to only include Chem + Species combinations
with multiple references. Then I will join them with the excel sheet of already collected data.

```{r load_multirefs, eval=FALSE}
# Reference Multiples
multiRef_ChemSpec <- cvt %>%
  ungroup() %>%
  distinct(analyte_dtxsid, species, document_id) %>%
  group_by(analyte_dtxsid, species) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 1) %>%
  dplyr::select(!n)
multiRef_ChemSpec %>% nrow() # Surprisingly only 15 Chem + Species have multiple references

```


### Evaluating error for the NCA estimations
Some chemicals have one observation for a timepoint but not for others, which
then each timepoint gets a random error value so that `PK::nca()` can run.
Here I evaluate 100 random seeds and the differences in values of NCA estimated parameters.

```{r NCA_error_eval, eval=FALSE}

# Which Chemical Species Route Media Dose groups have the randomness?
my_pk$data %>%
  group_by(Chemical, Species, Reference, Route, Media, Dose, Time) %>%
  summarize(Count = n()) %>%
  group_by(Chemical, Species, Reference, Route, Media, Dose) %>%
  filter(any(Count == 1) && any(Count > 1)) %>%
  distinct(Chemical, Species, Reference, Route, Media, Dose) -> problem_set



# Evaluate 100 times
n_evals <- 100
evalNCA_df <- NULL
my_pk_new <- my_pk +
  settings_preprocess(suppress.message = TRUE)

for (i in 1:100) {
  seed_num <- 100 + i
  set.seed(seed_num)
  message(paste("Current seed:", seed_num))
  my_pk_new <- do_preprocess(my_pk_new)
  my_pk_new <- do_data_info(my_pk_new)
  
  this_nca <- my_pk_new$data_info$nca %>%
    select(-param_sd_z) %>%
    mutate(seed = as.factor(seed_num))
  evalNCA_df <- bind_rows(evalNCA_df, this_nca)
}

names(evalNCA_df)

evalNCA_df %>%
  group_by(Chemical, Species, Route, Media, Dose, param_name) %>%
  summarize(Average = mean(param_value[which(!is.infinite(param_value))], na.rm = TRUE),
            Median = median(param_value[which(!is.infinite(param_value))], na.rm = TRUE),
            StDev = sd(param_value[which(!is.infinite(param_value))], na.rm = TRUE),
            Min = min(param_value[which(!is.infinite(param_value))], na.rm = TRUE),
            Max = max(param_value[which(!is.infinite(param_value))], na.rm = TRUE),
            Unique_Values = length(unique(signif(param_value, 4))),
            Inf_Count = sum(is.infinite(param_value))) %>%
  filter(
    # Route %in% "iv",
    param_name %in% "Cmax"
    ) %>%
  View()
  
  
evalNCA_df %>%
  filter(param_name %in% c("tmax"),
         Route %in% "iv",
         is.finite(param_value),
         Species %in% c("rat", "human", "hamster"))  %>%
  ggplot(aes(x = param_value, y = Chemical)) +
  geom_point() +
  facet_grid(rows = vars(Route)) +
  theme_bw() +
  theme(axis.text.y = element_text(size = 5),
        axis.ticks.y = element_blank(),
        panel.grid.major = element_line(color = "grey70",
                                          linewidth = 0.4,
                                          linetype = "solid"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank())




set.seed(2023)
```

## Running dose-normalized, log-transformed, joint fits  

Dose-normalization, log10 transformation, time-scaling,
and a hierarchical model were the options that produced the least
amount of error in predictions and derived TK stats.
In addition, _L-BFGS-B_ ran significantly faster,
but _bobyqa_ produced predictions with slightly less error.


```{r Final_Options, eval=FALSE}
my_pk <- minimal_pk +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = TRUE,
                      suppress.messages = FALSE) +
  settings_optimx(method = c("bobyqa")) +
  scale_conc(dose_norm = TRUE, log10_trans = TRUE) +
  scale_time(new_units = "auto") +
  stat_error_model(error_group = vars(Chemical, Species, Reference)) 

my_pk <- do_preprocess(my_pk)
cvt_DTXSIDs <- unique(my_pk$data$Chemical)
length(cvt_DTXSIDs)

my_pk <- do_prefit(my_pk)


{
  start <- Sys.time()
  my_pk <- do_fit(my_pk, 
                  n_cores = 14)
  round(Sys.time() - start, 4)
}

my_pk$fit %>% unnest(fit) %>%
  pull(convcode) %>% table()
  # pull(xtime) %>% as.numeric() %>% `/`(60) %>% hist(breaks = 25)
```

## Analysis Plots

Next I will generate the figures for the paper. I will begin by collating the data
that I need. This data are generally accessible using functions/methods for evaluating
fitted `pk` objects.

```{r data_aggregation, eval=FALSE}
# Need the following data for any of the subsequent plots

# after fitting pk object for all cvt objects or reading the fitted pk object in `setup`
winmodel <- get_winning_model(my_pk)
my_preds <- inner_join(predict(my_pk, use_scale_conc = FALSE), winmodel)
my_residuals <- residuals(my_pk, use_scale_conc = FALSE) %>%
  inner_join(winmodel)
my_tkstats <- eval_tkstats(my_pk) %>% inner_join(winmodel) 
my_nca <- get_nca(my_pk)
all_my_data <- get_data(my_pk)


twofold_stats <- twofold_test(my_pk)

# Writing file to xlsx
writexl::write_xlsx(x = list(predictions = my_preds,
                             tkstats = my_tkstats),
                    path = paste0(Sys.getenv("FIG_DIR"),
                                  "Manu_Files/",
                                  format(Sys.Date(), "%d%B%Y"),
                                  "_Supp_Table2",
                                  ".xlsx"))



fe_df <- fold_errors(my_pk) %>% inner_join(winmodel)
# May need to change the use_scale_conc defaults
r2_df <- rsq(my_pk, use_scale_conc = FALSE) %>%
  inner_join(winmodel)
myAIC <- AIC(my_pk) %>%
  inner_join(winmodel)
myRMSE <- rmse(my_pk, method = "bobyqa",
               rmse_group = vars(Route, Media, Dose),
               use_scale_conc = FALSE) %>% 
  inner_join(winmodel)

# Something wrong with the summary method... maybe only use detects?
fold_errors_all <- fe_df %>%
  dplyr::filter(Detect %in% TRUE) %>%
  dplyr::group_by(!!!my_pk$data_group, model, method) %>%
  dplyr::summarize(avg_FoldErr = mean(Fold_Error, na.rm = TRUE),
                median_FoldErr = median(Fold_Error, na.rm = TRUE),
                within_2fold = sum(Fold_Error >= 0.5 & Fold_Error <= 2)/length(Fold_Error))

myRMSE_all <- myRMSE %>%
  dplyr::group_by(!!!my_pk$data_group, model, method) %>%
  dplyr::summarize(avg_MSE = mean(RMSE^2, na.rm = TRUE),
                median_MSE = median(RMSE^2, na.rm = TRUE))


my_coefs <- coef(my_pk) %>% inner_join(winmodel) %>% inner_join(myAIC)

# The following section of code summarizes the non-compartmental analysis tkstats
# and summarizes them into mean and standard deviation to make comparison with
# fitted statistics much easier!

summarized_tkstats <- my_tkstats %>% 
  dplyr::select(1:30) %>%
  distinct() %>%
  inner_join(my_tkstats %>%
              dplyr::select(Chemical:method, ends_with(".nca")) %>%
              group_by(Chemical, Species, Route, Media, Reference) %>%
              summarize(across(where(is.numeric), 
                               list(mean = mean, sd = sd))))


summarized_tkstats <- summarized_tkstats %>%
  group_by(Chemical, Species, Route, Media) %>%
  dplyr::select(where(is.numeric)) %>% 
  pivot_longer(cols = ends_with(".tkstats"),
               names_to = "stat_name",
               values_to = "stat_value") %>%
  pivot_longer(cols = ends_with(".nca_mean"),
               names_to = "nca_name",
               values_to = "nca_mean") %>%
  pivot_longer(cols = ends_with(".nca_sd"),
               names_to = "nca_sd_name",
               values_to = "nca_sd") %>%
  mutate(stat_name = stringr::str_extract(stat_name, "^.*(?=\\.)"),
         nca_name = stringr::str_extract(nca_name, "^.*(?=\\.)"),
         nca_sd_name = stringr::str_extract(nca_sd_name, "^.*(?=\\.)")) %>%
  filter(stat_name == nca_name, stat_name == nca_sd_name) %>%
  distinct() %>% 
  select(!c(nca_name, nca_sd_name))


chem_name_translate <- all_my_data %>%
  dplyr::select(Chemical, Chemical_Name) %>%
  dplyr::distinct()

```



### Figure 4A: Replicated timepoint variation in CvTdb

The purpose of Figure 4 is to illustrate the variability among replicate
time points per Chemical/Species/Reference/Route/Media/Dose group. 
This characterization is important as it can serve as a pre-fitting data check
and if the data are too variable it is likely `invivoPKfit` will struggle to
find an appropriate fit. One thing to consider is that there may be various factors
that contribute to data variability including but not limited to:  
-  Experimental design  
-  Technical precision  
-  Biological variation between subjects in different studies  

Additionally, this also contributes to supplemental figure 2.


```{r fig4A_supp2A, eval=FALSE}
all_my_data %>%
  filter(Detect %in% TRUE,
         exclude %in% FALSE,
         Dose > 0) %>%
  group_by(Chemical,
           Species,
           Reference,
           Route, 
           Media,
           Dose, Time) %>%
  filter(n() > 1,
         sum(is.na(Conc)) != n(),
         Conc > LOQ) %>% 
  summarize(normal = shapiro.test(log10(Conc))$p.value) %>% ungroup() %>%
  count(normal > 0.05)
  ggplot(aes(x = Conc, color = paste(Chemical, Species, Reference,
                                     Route, Media, Dose))) +
  geom_freqpoly() +
  theme(legend.position = "none")
  mutate(meanConc = mean(Conc, na.rm = TRUE)) %>% 
  ungroup() %>%
  rowwise() %>%
  mutate(foldConc = Conc / meanConc) %>% View("in_data")
  # filter(Route == "oral") %>%
  count(foldConc >= 0.5 & foldConc <= 2) #%>%
  {.[[2,2]]/(.[[1,2]] + .[[2,2]])}
# Stats for ALL | ORAL | IV
# 89.01% inside twofold | 87.13%  | 92.27%
# 2.21%  above twofold  | 2.63%   | 1.4%
# 8.77%  below twofold  | 10.24%  | 6.23%

pl4A <- all_my_data %>%
  filter(Detect %in% TRUE,
         exclude %in% FALSE,
         Dose > 0) %>%
  group_by(Chemical,
           Species,
           Reference,
           Route, 
           Media,
           Dose, Time) %>%
  filter(n() > 1,
         sum(is.na(Conc)) != n(),
         LOQ < Conc) %>%
  mutate(meanConc = mean(Conc, na.rm = TRUE)) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(foldConc = Conc / meanConc) %>%
  # Plotting
  ggplot(aes(x = foldConc)) +
  geom_histogram(binwidth = 0.2,
                 fill = "grey5",
                 color = "grey5",
                 linewidth = 0.4) +
  coord_cartesian(xlim =  c(0, 4),
                  ylim = c(0, 4000)) +
  scale_y_continuous(expand = c(0, 0),
                     breaks = c(0, 1000, 2000, 3000),
                     labels = c("0", "1", "2", "3")) +
  expand_limits(y = 0) +
  geom_vline(xintercept = c(0.5, 2), color = "red3", linetype = "dashed") +
  theme_classic() +
  labs(x = "Mean-normalized\nconcentration",
                y = "Observations\n(thousands)") +
  theme(text = element_text(size = 10),
        panel.border = element_rect(color = "black", linewidth = 1, fill = NA),
        panel.background = element_blank(),
        panel.grid.major.y = element_line(color = "grey90", linewidth = 0.4),
        axis.title = element_text(face = "bold"),
        axis.line = element_blank(),
        plot.background = element_blank(),
        axis.ticks.y = element_blank())

pl4A

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "NormalizedConcentrations_2023-05-08.png"),
       plot = pl4A,
       height = 2.2,
       width = 2.5,
       units = "in",
       device = "png",
       dpi = 300)


all_my_data %>%
  filter(Detect %in% TRUE,
         exclude %in% FALSE,
         Dose > 0) %>%
  group_by(Chemical,
           Species,
           Reference,
           Route, 
           Media,
           Dose, Time) %>%
  count() %>%
  mutate(Replicated = ifelse(n > 1, TRUE, FALSE)) %>%
  distinct() %>%
  # .$Replicated %>% table()
  ggplot(aes(fill = Replicated, x = "")) +
  geom_bar(position = "stack",
           color = "black") +
  labs(x = "", y = "Timepoints") +
  scale_fill_manual(values = c("black", "white")) +
  scale_y_continuous(expand = c(0, NA)) +
  theme_void() +
  theme(legend.position = "bottom")

```


### Figure 4A-2: Alternate version of Figure 4A

This alternate version of Figure 4A aims to simplify the assessment of replication
of datasets in invivoPKfit. In contrast to the original 4A, this will also result
in the inclusion of datasets with recorded standard deviation values
(i.e. non-indivudual animal data/summarized data).

The way this will work is by calculating the average and standard deviations
of individual animal data
(eliminating individual animal data that does not have replicates)
then testing the following:

$$
\frac{\mu + 2\sigma}{\mu} \leq 2
$$

Which essentially tests whether, at least 95% of data is within a factor of 2.
The result is a bar chart that shows how many timepoints with replicate values
passed this test. It minimizes the double (or more) counting of timepoints with
multiple replicates from individual animal data.


```{r fig4A-2-alt, eval=FALSE}
# With the mapped column names
iad_summary <- all_my_data %>% filter(Conc > 0, N_Subjects == 1, Dose > 0) %>%
  group_by(Chemical, Species, Route, Media, Dose, Reference, Time) %>%
  filter(n() > 1) %>%
  summarize(conc_sd_calc = sd(Conc),
            conc_avg_calc = mean(Conc),
            n_subjects_in_series = n())

sud_summary <- all_my_data %>% filter(Conc > 0, N_Subjects > 1,
                                      !is.na(Conc_SD), Dose > 0) %>%
  mutate(conc_sd_calc = Conc_SD,
         conc_avg_calc = Conc,
         n_subjects_in_series = N_Subjects) %>%
  distinct(Chemical, Species, Route, Media, Dose, Reference, Time,
           conc_sd_calc, conc_avg_calc, n_subjects_in_series)

combined_summary <- bind_rows(sud_summary, iad_summary) %>%
  rowwise() %>%
  mutate(twofold_95 = ifelse((conc_avg_calc + (2*conc_sd_calc))/conc_avg_calc < 2,
                             TRUE, FALSE))

table(combined_summary$twofold_95) # 86.57% have z-score within +/-2

pl4A <- combined_summary %>% ungroup() %>%
  count(twofold_95) %>%
  ggplot(aes(x = twofold_95, fill = twofold_95, y = n)) +
  geom_col(position = position_stack(),
           color = "black", linewidth = 1) +
  coord_cartesian(ylim = c(0, 5000)) +
  scale_y_continuous(expand = c(0, NA),
                     breaks = c(0, 1000, 2000, 3000, 4000, 5000),
                     labels = c("0", "1", "2", "3", "4", "5")) +
  scale_fill_manual(values = c("black", "white")) +
  theme_classic() +
  labs(x = "95% of observations\nwithin factor of 2",
                y = "Observations\n(thousands)") +
  theme(text = element_text(size = 10),
        panel.border = element_rect(color = "black", linewidth = 1, fill = NA),
        panel.background = element_blank(),
        panel.grid.major.y = element_line(color = "grey90", linewidth = 0.4),
        axis.title = element_text(face = "bold"),
        axis.line = element_blank(),
        plot.background = element_blank(),
        axis.ticks.y = element_blank(),
        legend.position = "none")


```


### Figure 4B: Variation over time in CvTdb data.

Here the goal is to evaluate whether particular timepoints throughout CvT data
are particularly susceptible to high variability. To do this, we create a 
relative time scale anchored by $t_{max}$ and $t_{last}$.

```{r fig4B-cowplot, eval=FALSE}

pl4B <- all_my_data %>%
  group_by(Chemical,
           Species,
           Reference,
           Route,
           Dose, Time) %>%
  filter(n() > 1,
         sum(is.na(Conc)) != n(),
         exclude == FALSE) %>%
  mutate(meanConc = mean(Conc, na.rm = TRUE)) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(foldConc = Conc / meanConc) %>%
  inner_join(my_tkstats %>%
              dplyr::select(Chemical, Species,
                            Route, Media,
                            tmax = tmax.nca) %>%
              filter(!is.na(tmax))) %>%
  group_by(Chemical,
           Species,
           Reference,
           Route,
           Media,
           Dose) %>%
  mutate(
         normTime = ifelse(
           Route == "iv",
           1 + Time/max(Time),
           ifelse(
             Time > tmax,
             ((Time - tmax)/max(Time)) + 1,
             0.5 + Time/(2*tmax)
           )
         )) %>%
  ggplot(aes(
    x = normTime,
    y = foldConc
  )) +
  geom_point(alpha = 0.1, size = 0.7) +
  geom_vline(xintercept = 1, color = "blue",
             linewidth = 0.8, linetype = "dashed") +
  geom_vline(xintercept = 2, color = "green4",
             linewidth = 0.8, linetype = "dashed") +
  geom_hline(yintercept = c(0.5, 2), color = "red3",
             linewidth = 0.8, linetype = "dashed") +
  facet_grid(cols = vars(Route),
             scales = "free_x") +
  labs(x = "ADME-Normalized Time",
       y = "Mean-Normalized\nConcentration") +
  theme(text = element_text(size = 10),
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_text(face = "bold"),
        panel.spacing = unit(0.125, units = "in"),
        plot.background = element_blank(),
        legend.position = "none")

pl4B

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "ADME_NormTime-NormConcs_onlyDetects_2024-05-16.png"),
       height = 4,
       width = 5,
       units = "in",
       dpi = 300)


# Make the Combination Plot----

plot_grid(pl4A, pl4B, labels = c("A", "B"),
                     align = "h", axis = "bt", rel_widths = c(1, 2))


figure4 <- plot_grid(pl4A, pl4B, labels = c("A", "B"),
                     align = "h", axis = "bt", rel_widths = c(1, 1.75))

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "Figure5alt_onlyDetects_2024-05-08.png"),
       plot = figure4,
       bg = "white",
       height = 3.25,
       width = 6.5,
       units = "in",
       dpi = 300)


# Extra Plot: Model error over ADME-normalized time!
my_preds %>% 
  inner_join(my_tkstats %>%
              dplyr::select(Chemical, Species,
                            Route, Media,
                            tmax = tmax.nca) %>%
              filter(!is.na(tmax))) %>%
  group_by(Chemical,
           Species,
           Route,
           Media,
           Dose) %>%
  mutate(normTime = ifelse(
           Route == "iv",
           1 + Time/max(Time),
           ifelse(
             Time > tmax,
             ((Time - tmax)/max(Time)) + 1,
             0.5 + Time/(2*tmax)
           )
         )) %>%
  group_by(model, method,
           Chemical, Species, Route, Media,
           Dose, normTime) %>%
  summarize(RMSLE = sqrt(sum((log10(Conc) - log10(Conc_est))^2)/n())) %>%
  # inner_join(tricky_chems) %>% View("modelErr_overTime")
  ###
  # group_by(model, method,
  #          Chemical, Species, Route, Media,
  #          Dose) %>%
  # summarize(RMSLE_diff = range(RMSLE)[2] - range(RMSLE)[1]) %>%
  # filter(RMSLE_diff > 10) %>% distinct(Chemical, Species) -> tricky_chems
  ggplot(aes(
    x = normTime,
    y = RMSLE
  )) +
  geom_point(alpha = 0.1, size = 0.7) +
  geom_point(data = . %>% inner_join(tricky_chems),
             alpha = 0.1, size = 0.7, color = "red3") +
  geom_vline(xintercept = 1, color = "blue",
             linewidth = 0.8, linetype = "dashed") +
  geom_vline(xintercept = 2, color = "green4",
             linewidth = 0.8, linetype = "dashed") +
  facet_grid(cols = vars(Route),
             scales = "free_x") +
  labs(x = "ADME-Normalized Time",
       y = "RMSLE",
       title = "RMSLE over the course of an experiment") +
  theme(text = element_text(size = 10),
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_text(face = "bold"),
        panel.spacing = unit(0.125, units = "in"),
        plot.background = element_rect(color = "white"),
        legend.position = "none")

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "RMLE_overADME_time",
              ".png"),
       height = 3,
       width = 7,
       units = "in",
       dpi = 300)




my_preds %>% 
  inner_join(my_tkstats %>%
              dplyr::select(Chemical, Species,
                            Route, Media,
                            tmax = tmax.nca) %>%
              filter(!is.na(tmax))) %>%
  group_by(Chemical,
           Species,
           Route,
           Media,
           Dose) %>%
  mutate(normTime = ifelse(
           Route == "iv",
           1 + Time/max(Time),
           ifelse(
             Time > tmax,
             ((Time - tmax)/max(Time)) + 1,
             0.5 + Time/(2*tmax)
           )
         )) %>%
  group_by(model, method,
           Chemical, Species, Route, Media,
           Dose, normTime) %>%
  summarize(RMSLE = sqrt(sum((log10(Conc) - log10(Conc_est))^2)/n())) %>%
  mutate(TimeCat = ifelse(normTime > 1, "elimination", "absorption")) %>%
  ggplot(aes(x = RMSLE)) +
  geom_histogram() +
  facet_grid(rows = vars(Route),
             cols = vars(TimeCat)) +
  theme_bw()



ggsave(paste0(Sys.getenv("FIG_DIR"),
              "RMLE_overADME_time_histograms",
              ".png"),
       height = 6,
       width = 6,
       units = "in",
       dpi = 300)

```


### Supp. Figure 2: Concentration and final time-points have wide range


```{r cvt_analysis, eval=FALSE}
data_range <- all_my_data %>%
  filter(Detect) %>%
  group_by(Chemical, Species, Reference, Media, Route, Dose, Dose.Units) %>%
  summarize(maxT = max(Time)/24,
         concRange = log10(max(Conc)/min(Conc))) %>%
  ungroup()
  
sf_2A <- all_my_data %>%
  filter(Detect, N_Subjects == 1) %>%
  group_by(Chemical, Species, Reference, Media, Route, Dose, Dose.Units, Time) %>%
  mutate(normConc = Conc/mean(Conc)) %>%
  ggplot(aes(x = normConc)) +
  scale_y_continuous(expand = expansion(mult = c(0,0.15))) +
  xlim(0, 4) +
  geom_histogram(,
                 bins = 25,
                 color = "grey5",
                 fill = "grey5") +
  geom_vline(xintercept = c(0.5, 2), color = "red3", linetype = "dashed") +
  labs(x = "Normalized concentrations",
       y = "Observations") +
  theme(aspect.ratio = 1,
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 11))
   
  
sf_2C <- data_range %>%
  ggplot(aes(x = maxT)) +
  geom_histogram(fill = "grey5",
                 bins = 40,
                 color = "grey5") +
  scale_x_log10(labels = scales::number,
                breaks = c(0.1, 1, 7, 30, 365)) +
  # scale_y_continuous(expand = c(0, 0),
  #                    limits = c(0, 60),
  #                    breaks = c(0, 10, 20, 30, 40, 50)) +
  labs(x = "Day of final Timepoint",
       y = "Count") +
  theme(aspect.ratio = 1,
        text = element_text(size = 10),
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        axis.ticks = element_blank(),
        axis.line = element_blank())

sf_2C

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "SFig2C_TimePoints_2024-05-08.png"),
       plot = sf_2C,
       height = 4,
       width = 4,
       units = "in",
       dpi = 300)


sf_2B <- data_range %>%
  ggplot(aes(x = concRange)) +
  geom_histogram(fill = "grey5",
                 bins = 40,
                 color = "grey5") +
  scale_y_continuous(expand = c(0, 0),
                     limits = c(0, 50),
                     breaks = c(0, 25, 50)) +
  labs(x = "log10(Concentration Range)",
       y = "Count") +
  theme(aspect.ratio = 1,
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 11))


ggsave(paste0(Sys.getenv("FIG_DIR"),
              "SFig2B_ConcRange_2024-05-08.png"),
       plot = sf2B,
       height = 4,
       width = 4,
       units = "in",
       dpi = 300)

sf_2BC <- plot_grid(sf_2B, sf_2C,
                    labels = c("B", "C"), 
                    nrow = 2,
                    label_size = 20)



plot_grid(sf_2A, sf_2BC,
          labels = c("A", ""),
          label_size = 20,
          align = "h")

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "SFig2_ConcTimeRanges_2024-05-08.png"),
       height = 4,
       width = 6,
       units = "in",
       dpi = 300)

```



### Supp Figure 3: invivoPKfit model performance


```{r sFig3-model_performance, eval=FALSE}


my_preds %>%
  rowwise() %>%
  mutate(Pred_Obs = Conc_est/Conc) %>%
  filter(is.finite(Pred_Obs),
         model %in% c("model_1comp", "model_2comp")) %>%
  mutate(pass = ifelse(Pred_Obs < 0.5, TRUE, FALSE)) %>%
  pull(pass) %>% table() %>%
  {.[[2]]/(.[[1]] + .[[2]])}
  ggplot(aes(x = Pred_Obs)) +
  geom_histogram(binwidth = 0.25,
                 fill = "grey5") +
  scale_x_log10(limits = c(1E-5, 1E5),
                labels = scales::label_math(format = log10)) +

  expand_limits(y = 0) +
  geom_vline(xintercept = c(0.5, 2), color = "red3", linetype = "dashed") +
  facet_grid(cols = vars(model),
             rows = vars(Route)) +
  labs(x = "Dose-normalized\nPredicted/Observed",
       y = "Number of Observations") +
  theme_classic() +
  theme(aspect.ratio = 1,
        panel.border = element_rect(color = "black", fill = NA),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.4))


# 99.18% of Pred_Obs are finite
# 18.89% Are above two-fold
# 21.52%  Are below two-fold
# 59.62% Are within twofold

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "PredictedObserved_compartmentModels_2024-05-08.png"),
>>>>>>> feature/Rclearance_comparison
       height = 6, width = 6)
  

```



### Figures 5 and Supplemental Figures 4 & 5: Model performance vs Data Variability

Here we examine the performance of "best fit" models with relation to data variability.
Please note that in supplemental Figure 3, the data with summarized observations
(mean and sd) were included. Here, because we are trying to specifically compare
data variability with model performance, we look at data with replicated timepoint observations, which are largely data with individual animal data.

```{r fig5-modelPerform-v-dataVar, eval=FALSE}
# pl_5A <-
  my_preds %>% 
  right_join(winmodel) %>%
  group_by(Chemical,
           Species,
           Route, Media,
           Dose, Time) %>%
  filter(n() > 1,
         sum(is.na(Conc)) != n(),
         # model %in% c("model_flat"),
         exclude %in% FALSE,
         Detect %in% TRUE) %>%
  mutate(meanConc = mean(Conc, na.rm = TRUE)) %>%
  ungroup() %>%
  distinct() %>%
  rowwise() %>%
  mutate(foldConc = Conc / meanConc,
         foldPred = Conc_est / Conc) %>% 
  # For percentages
  ungroup() %>%
  filter(model %in% c("model_flat")) %>%
  count((foldPred >= 0.5 & foldPred <= 2) &
          (foldConc >= 0.5 & foldConc <= 2)) %>%
  {100*.[[2,2]]/(.[[1,2]] + .[[2,2]])}
  # For Plotting
  ggplot(aes(
    y = foldPred,
    x = foldConc
  )) +
  geom_bin2d(bins = 40, color = NA) +
  geom_hline(yintercept = c(0.5, 2), linetype = "dashed") +
  geom_vline(xintercept = c(0.5, 2), linetype = "dashed") +
  facet_grid(cols = vars(model)) +
  scale_x_log10(labels = scales::label_math(format = log10),
                limits = c(0.001, 100)) +
  scale_y_log10(labels = scales::label_math(format = log10),
                limits = c(0.0001, 10000)) +
  scale_fill_viridis_c(option = "cividis",
                       limits = c(1, 100),
                       oob = scales::oob_squish) +
  labs(y = "Model Error",
       x = "Data Variability") +
  theme(aspect.ratio = 1,
        panel.border = element_rect(color = "black", fill = NA, size = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank())

pl_5A
ggsave(paste0(Sys.getenv("FIG_DIR"),
              "ModelPerformance_vDataVariability_2024-05-08.png"),
       height = 3,
       width = 6.5,
       device = "png",
       dpi = 300,
       units = "in")  
  
my_table <- data.frame(
  c("Both within a factor of 2",
    "Model too variable",
    "Data too variable",
    "Both outside a factor of 2"),
  c(50.15, 36.28, 3.34, 10.23),
  c(68.45, 20.94, 3.14, 7.46),
  c(16.28, 71.29, 1.07, 11.35),
  c(62.36, 26.53, 3.01, 8.09))


names(my_table) <- c(" ","1-compartment (%)", "2-compartment (%)", "Flat (%)", "Overall (%)")

library(flextable)
library(officer)

flextable(my_table) %>%
  border_inner() %>%
  fontsize(part = "all", size = 11) %>%
  bold(part = "all", j = 5)

table_plot <- gen_grob(flextable(my_table) %>%
                         border_inner() %>%
                         fontsize(part = "all", size = 10) %>%
                         bold(part = "all", j = 5) %>%
                         autofit())


dual_plot <- plot_grid(pl_5A, table_plot, ncol = 1, align = "v",
          rel_heights = c(1, 0.5))


ggsave(paste0(Sys.getenv("FIG_DIR"),
              "ModelPerformance_vDataVariability_wTable_2024-05-16.png"),
       plot = dual_plot,
       height = 4.5,
       width = 6.5,
       device = "png",
       bg = "white",
       dpi = 300,
       units = "in")  
```

### Figure 5Alt

```{r fig5Alt, eval=FALSE}
# Redo combined summary
combined_summary <- bind_rows(sud_summary, iad_summary) %>%
  rowwise() %>%
  mutate(twofold_95 = ifelse((conc_avg_calc + (2*conc_sd_calc))/conc_avg_calc < 2,
                             TRUE, FALSE))

# Now
this_preds <- inner_join(predict(my_pk), winmodel) %>%
  rowwise() %>% mutate(foldPred = Conc_est/Conc) %>%
  distinct(model, method, Chemical, Species, Route, Media, Dose, Time, foldPred) %>%
  group_by(model, method, Chemical, Species, Route, Media, Dose, Time) %>%
  summarize(avgFE = mean(foldPred, na.rm = TRUE))

pl_5Alt <- this_preds %>%
  inner_join(combined_summary, by = join_by(Chemical, Species,
                                            Route, Media,
                                            Dose, Time)) %>%
  filter(!is.na(model), avgFE > 0) %>% 
  # 
  # For Plotting
  ggplot(aes(
    y = avgFE,
    x = twofold_95
  )) +
  geom_bin2d(bins = 40, color = NA) +
  geom_hline(yintercept = c(0.5, 2), linetype = "dashed", linewidth = 1, color = "red3") +
  scale_y_log10(labels = scales::label_math(format = log10),
                limits = c(0.0001, 10000)) +
  scale_fill_viridis_c(option = "cividis",
                       limits = c(1, 200),
                       oob = scales::oob_squish) +
  labs(y = "Model Error",
       x = "95% of data within 2-fold") +
  theme(aspect.ratio = 1,
        panel.border = element_rect(color = "black", fill = NA, size = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank())

pl_5Alt
ggsave(paste0(Sys.getenv("FIG_DIR"),
              "ModelPerformance_vDataVariability_2024-05-16.png"),
       height = 4.5,
       width = 4.5,
       device = "png",
       bg = "white",
       dpi = 300,
       units = "in")  

this_preds %>%
  inner_join(combined_summary, by = join_by(Chemical, Species,
                                            Route, Media,
                                            Dose, Time)) %>%
  filter(!is.na(model), avgFE > 0) %>% ungroup() %>%
  filter(model == "model_2comp") %>%
  count(!(avgFE >= 0.5 & avgFE <= 2) & !twofold_95) %>%
  {100*.[[2,2]]/(.[[1,2]] + .[[2,2]])} %>% round(digits = 1)

# Table

names(my_table) <- c(" ","1-compartment (%)", "2-compartment (%)", "Flat (%)", "Overall (%)")

library(flextable)
library(officer)

flextable(my_table) %>%
  border_inner() %>%
  fontsize(part = "all", size = 11) %>%
  bold(part = "all", j = 5)

table_plot <- gen_grob(flextable(my_table) %>%
                         border_inner() %>%
                         fontsize(part = "all", size = 10) %>%
                         bold(part = "all", j = 5) %>%
                         autofit())


dual_plot <- plot_grid(pl_5Alt, table_plot, ncol = 1, align = "v",
          rel_heights = c(1, 0.5))

dual_plot
ggsave(paste0(Sys.getenv("FIG_DIR"),
              "ModelPerformance_vDataVariability_wTable_2024-05-16.png"),
       plot = dual_plot,
       height = 4.5,
       width = 6.5,
       device = "png",
       bg = "white",
       dpi = 300,
       units = "in")  

```


### Figure 6: Multiple goodness-of-fit metrics validate model performance
Here we analyze and validate model performance per data group using R-squared,
RMSE, and fraction of predictions that are within 2-fold for each Chemical,
Species, Route, Media, and Dose groupings.

```{r fig6-goodness-of-fit, eval=FALSE}
my_df <- left_join(fold_errors_all, r2_df) %>% inner_join(myAIC) %>% inner_join(myRMSE_all) %>%
  inner_join(winmodel)

mypl <-
  ggplot(data = my_df,
               aes(
                 x = within_2fold,
                 y = Rsq,
                 color = model
               )) +
  geom_point() +
  geom_abline(slope = 1, color = "red4", linetype = "longdash") +
  scale_color_manual(values = c("#0398FC", "#D68E09", "black")) +
    coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  labs(x = "Fraction of predictions within 2-fold",
       y = "R-squared value") +
  theme(aspect.ratio = 1,
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        legend.position = "none",
        legend.title = element_blank(),
        legend.key = element_blank())
  
panelA_plot <- ggExtra::ggMarginal(mypl, groupFill = TRUE,
                    type = "histogram",
                    xparams = list(binwidth = 0.1),
                    yparams = list(binwidth = 0.1))
ggsave(filename = paste0(Sys.getenv("FIG_DIR"),
                         "R2_within2fold_comparison.png"),
       plot = ggExtra::ggMarginal(mypl, groupFill = TRUE,
                    type = "histogram",
                    xparams = list(binwidth = 0.05),
                    yparams = list(binwidth = 0.05)),
       height = 5,
       width = 5,
       units = "in")

panelB_plot <- ggplot(data = myRMSE,
               aes(
                 x = log10(RMSE),
                 color = model,
                 fill = model
               )) + 
  geom_histogram(bins = 50) +
  labs(y = "Count") +
  scale_color_manual(values = c("#0398FC", "#D68E09", "grey10")) +
  scale_fill_manual(values = c("#0398FC", "#D68E09", "grey10")) +
  # scale_y_continuous(breaks = scales::pretty_breaks(n = 5),
  #                    expand = c(0,0.1)) +
  facet_grid(rows = vars(model),
             cols = vars(Route)) +
  theme(text = element_text(size = 10),
        aspect.ratio = 0.6,
    panel.border = element_rect(color = "black", fill = NA, size = 1),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        strip.background = element_blank(),
    panel.spacing.y = unit(0.125, units = "in"),
        legend.position = "bottom",
        legend.title = element_blank())
panelB_plot

ggsave(filename = paste0(Sys.getenv("FIG_DIR"),
                         "RMSEs_winningmodel_LBFGSB_zero1E-6_RouteFacet_notNormalized.png"),
       height = 4,
       width = 6,
       units = "in")

legend <- get_legend(panelB_plot)

plot_grid(plot_grid(panelA_plot,
                   panelB_plot + theme(legend.position = "none"), labels = c("A", "B"),
                   axis = "tb", align = "h", rel_heights = c(1,1)), legend,
          ncol = 1,
          rel_heights = c(1, 0.1))
ggsave(filename = paste0(Sys.getenv("FIG_DIR"),
                         "CombinedPlot_Rsquared_RMSE.png"),
       height = 4,
       width = 6.5,
       bg = "white",
       units = "in")


# Classification analysis
clFire <- readxl::read_xlsx(paste("C:/Users/GPADILLA",
                                  "OneDrive - Environmental Protection Agency (EPA)",
                                  "Profile/Documents",
                                  "classified_cvt_2024_05_09.xlsx", sep = "/"))

my_df %>%
  left_join(clFire %>% distinct(Identifier, superclass, class),
            by = c("Chemical" = "Identifier")) %>%
  ggplot(aes(x = within_2fold, y = Rsq, color = superclass)) +
  geom_point() +
  facet_wrap(~superclass) +
  theme_bw()


winmodel %>%
  left_join(clFire %>% distinct(Identifier, superclass, class),
            by = c("Chemical" = "Identifier")) %>% View()

my_data <- get_data(my_pk)
my_data %>% 
  filter(N_Subjects == 1) %>%
  group_by(Chemical, Species, Reference,
           Route, Media,
           Dose, Time) %>%
  summarize(meanConc = Conc/mean(Conc/Dose)/Dose)


my_tkstats %>%
  left_join(clFire, by = c("Chemical" = "DTXSID")) %>%
  distinct(Chemical, Species, Route, Media, Reference, method, model,
           halflife.tkstats, halflife.nca,
           superclass) %>%
  ggplot(aes(y = Chemical,
             fill = superclass)) +
  geom_point(aes(x = halflife.tkstats), shape = 21) +
  geom_point(aes(x = halflife.nca), shape = 22) +
  scale_x_log10() +
  facet_grid(rows = vars(superclass), scales = "free", space = "free") +
  theme_bw() +
  theme(strip.text.y = element_text(hjust = 0, angle = 0))

```


### Supp. Fig. 6 Examples fits for chemicals with R-squared and within 2-fold
```{r goodness-of-fit_exampleFits, eval = FALSE}
pl <- plot(my_pk, use_scale_conc = TRUE, best_fit = TRUE,
           drop_nonDetect = FALSE, log10_C = FALSE)

ex_fits <- pl %>%
  filter(Chemical %in% c("DTXSID3020833",
                         "DTXSID00216205",
                         "DTXSID3038305",
                         "DTXSID1022845")) %>%
  pull(final_plot)


cowplot::plot_grid(plotlist = list(ex_fits[[2]], ex_fits[[3]],
                                   ex_fits[[1]], ex_fits[[4]]))

ggsave(filename = paste0(Sys.getenv("FIG_DIR"),
                         "exampleFits_Rsq_within2fold.png"),
       height = 12,
       width = 12)

```



### Supp. Fig. 7: Distribution of Sigmas in CvTdb data

```{r sFig4-sigmaDistribution, eval=FALSE}


my_coefs <- inner_join(get_winning_model(my_pk), coef(my_pk))
my_coefs %>% inner_join(get_data_summary(my_pk)) -> my_coefs


my_coefs %>%
  mutate(model = 
           case_when(
             model == "model_1comp" ~ "1-compartment",
             model == "model_2comp" ~ "2-compartment",
             model == "model_flat"  ~ "Null"
           )) %>%
  ggplot(aes(x = sigma_value/n_obs)) +
  geom_histogram(bins = 15,
                 color = NA, fill = "grey5") +
  scale_x_log10(labels = scales::label_math(format = log10)) +
  facet_grid(cols = vars(model)) +
  labs(x = "Size-normalized Sigma Value",
       y = "Number of Observations") +
  theme(panel.border = element_rect(color = "black", fill = NA, size = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        plot.title = element_text(hjust = 0.5),
        axis.ticks = element_blank(),
        axis.line = element_blank())

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "NormalizedSigma_Distributions_2024-02.png"),
       height = 3, width = 5)

```



### Figure 7: Comparing derived TK stats with human TK stats from Lombardo et al.

This meta-analysis compares the TK stats from model fits with other published studies.


```{r Lombardo_Comparison, eval=FALSE}
cvt_DTXSIDs <- unique(my_pk$data$Chemical)
# First things first, let's load the data from Lombardo et al.
lombardo <- readxl::read_xlsx(
  paste0(Sys.getenv("FIG_DIR"),
         "Lombardo2018-Supplemental_82966_revised_corrected.xlsx"),
  skip = 8)


l_batch_search <- readxl::read_xlsx(
  paste0(Sys.getenv("FIG_DIR"),
         "LombardoBatchSearch_Name.xlsx"),
  sheet = "Main Data"
)

  
l_batch_search <- l_batch_search[c("INPUT", "CASRN","DTXSID")] %>%
  distinct() %>%
  right_join(lombardo[c("Name", "CAS #")], by = c("CASRN" = "CAS #", "INPUT" = "Name"))



l_noNamesCASRN <- readxl::read_xlsx(
  paste0(Sys.getenv("FIG_DIR"),
         "LombardoBatchSearch_CASRNnoName.xlsx"),
  sheet = "Main Data"
) %>%
  dplyr::select(CASRN = INPUT, DTXSID)

l_curatedDTX <- read_tsv(paste0(Sys.getenv("FIG_DIR"),
                         "CuratedIDs_lombardo.txt")) %>%
  rename(INPUT = Name)


l_batch_search <- l_batch_search %>%
  left_join(l_noNamesCASRN, by = "CASRN") %>%
  mutate(DTXSID = coalesce(DTXSID.x, DTXSID.y)) %>%
  dplyr::select(-DTXSID.x, -DTXSID.y)
  # View()
  # left_join(l_curatedDTX, by = "INPUT") %>%
  # mutate(DTXSID = coalesce(DTXSID.x, DTXSID.y)) %>%
  # dplyr::select(-DTXSID.x, -DTXSID.y)
# Now all but two of the IDs are unidentified

lombardo <- lombardo %>%
  right_join(l_batch_search, by = c("Name" = "INPUT"))


####
lombard_abbr <- lombardo %>% dplyr::select(DTXSID,
                                           hVss = `human VDss (L/kg)`,
                                           hCltot = `human CL (mL/min/kg)`,
                                           halflife = `terminal  t1/2 (h)` ) %>%
  filter(DTXSID %in% cvt_DTXSIDs) %>%
  left_join(chem_name_translate, by = c("DTXSID" = "Chemical"))

# 15 chemicals in common with values for both
lombardo_comparison <- my_tkstats %>%
  dplyr::select(DTXSID = Chemical, Species,
                model, Vss.tkstats, CLtot.tkstats) %>%
  distinct() %>%
  inner_join(lombard_abbr, by = "DTXSID") %>%
  # filter(!is.na(Vss.tkstats)) %>%
  arrange(halflife)

comparable_ids <- lombardo_comparison %>% pull(DTXSID)

lombard_abbr <- lombard_abbr %>%
  mutate(Species = "human", model = "Lombardo et al.") %>%
  rename(Vss = hVss, CLtot = hCltot) %>%
  mutate(CLtot = CLtot*60/1000) %>% # Lombardo reports this as mL/min/kg, need L/h/kg
  filter(DTXSID %in% comparable_ids) %>%
  mutate(Chemical_Name = reorder(Chemical_Name, halflife))

lombardo_comparison <- my_tkstats %>%
  dplyr::select(DTXSID = Chemical, Species,
                model, Vss.tkstats, CLtot.tkstats, halflife.tkstats) %>%
  filter(DTXSID %in% comparable_ids) %>%
  left_join(chem_name_translate, by = join_by(DTXSID == Chemical)) %>%
  distinct() %>%
  rename(Vss = Vss.tkstats, CLtot = CLtot.tkstats, halflife = halflife.tkstats) %>%
  bind_rows(lombard_abbr) %>%
  mutate(model = ifelse(str_detect(model, "^model"), "invivoPKfit", model),
         Chemical_Name = factor(Chemical_Name,
                                levels = levels(lombard_abbr$Chemical_Name)))

lombardo_comparison %>%
  pivot_longer(cols = c("Vss", "CLtot", "halflife")) %>%
  mutate(name = factor(name, levels = c("halflife", "Vss", "CLtot"))) %>%
  ggplot(mapping = aes(
    x = log10(value),
    y = Chemical_Name
  )) +
  geom_point(aes(color = model,
                 shape = Species),
             position = position_dodge(0.7),
             size = 5/.pt, stroke = 2.5/.pt) +
  facet_grid(cols = vars(name),
             scales = "free_x") +
  scale_shape_manual(values = c(21, 22, 24),
                     breaks = c("human", "dog", "rat")) +
  scale_color_manual(values = c("black", "#1064c9")) +
  guides(color = guide_legend(override.aes = list(shape = 21),
                              nrow = 2,
                              title.position = "top",
                              title.hjust = 0.5),
         shape = guide_legend(nrow = 1,
                              title.position = "top",
                              title.hjust = 0.5)) +
  theme(panel.border = element_rect(color = "black", fill = NA, linewidth = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold", size = 12),
        text = element_text(size = 10),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text = element_text(face = "bold", size = 6),
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        legend.position = "bottom",
        legend.key = element_blank(),
        legend.title = element_text(face = "bold"),
        legend.text = element_text())

ggsave(filename = paste0(Sys.getenv("FIG_DIR"),
                         "lombardoComparison_Figure8_2024_named.png"),
       height = 7,
       width = 6.5,
       device = "png", dpi = 300)
  


```


### Supp. Fig. 7 Histogram of Lombardo Vss and InvivoPKfit & another meta-analysis


```{r otherMeta-analysis, eval=FALSE}

# Histograms
lombardo_hist <- data.frame(Chemical = c(lombardo$DTXSID,
                              my_tkstats$Chemical),
                            Vss = c(lombardo$`human VDss (L/kg)`,
                              my_tkstats$Vss.tkstats),
                            halflife = c(lombardo$`terminal  t1/2 (h)`,
                              my_tkstats$halflife.tkstats),
                            Source = c(rep_len("lombardo",
                                    length.out = nrow(lombardo)),
                              rep_len("invivoPKfit",
                                      length.out = nrow(my_tkstats))))


sfig4A <- lombardo_hist %>% 
  ggplot(aes(x = log2(Vss), color = Source,
             group = Source)) +
  geom_freqpoly(aes(y = after_stat(ndensity)),
                linewidth = 2/.pt,
                bins = 20) +
  labs(y = "Scaled Frequency",
       x = "Vss") +
  scale_x_continuous(labels = scales::label_math(expr = 2^.x)) +
  scale_color_manual(values = c("black", "#1064c9")) +
  guides(color = guide_legend(nrow = 2, linewidth = 1)) +
  theme(panel.border = element_rect(color = "black", fill = NA, linewidth = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold", size = 12),
        text = element_text(size = 10),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.key = element_blank(),
        legend.title = element_text(face = "bold"),
        legend.text = element_text())

sfig4A
other_meta <- read_csv(
  file = paste0(Sys.getenv("FIG_DIR"), "SupTableInVivoDatandPreds.csv")) %>%
  dplyr::select(DTXSID, fbioh, fbior) %>%
  filter(DTXSID %in% my_tkstats$Chemical)


sfig4B <- other_meta %>% left_join(my_tkstats, by = c("DTXSID" = "Chemical")) %>%
  filter(Species %in% c("rat")) %>%
  filter(!is.na(Fgutabs.tkstats),
         !is.na(fbior)) %>%
  distinct(DTXSID, Species,
           Fgutabs.tkstats, fbior) %>%
  pivot_longer(cols = c(Fgutabs.tkstats, fbior),
               names_to = "Source",
               values_to = "Fgutabs") %>%
    mutate(Source = ifelse(str_detect(Source, "tkstats"), "invivoPKfit",
                           "Honda et al.")) %>%
  left_join(chem_name_translate, by = join_by(DTXSID == Chemical)) %>%
  ggplot(mapping = aes(
    x = Fgutabs,
    y = reorder(Chemical_Name, Fgutabs)
  )) +
  geom_point(aes(color = Source),
             shape = 24,
             position = position_dodge(0.7),
             size = 5/.pt, stroke = 2.5/.pt) +
  scale_color_manual(values = c("black", "green4"),
                     breaks = c("invivoPKfit", "Honda et al.")) +
  labs(x = "Oral Bioavailability") +
  guides(color = guide_legend(nrow = 2)) +
  theme(panel.border = element_rect(color = "black", fill = NA, linewidth = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold", size = 12),
        text = element_text(size = 10),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text = element_text(face = "bold"),
        axis.title.y = element_blank(),
        legend.position = "bottom",
        legend.key = element_blank(),
        legend.title = element_text(face = "bold"),
        legend.text = element_text())


plot_grid(sfig4A, sfig4B, align = "h", axis = "bt",
          rel_widths = c(1,2),
          labels = c("A", "B"))
ggsave(filename = paste0(Sys.getenv("FIG_DIR"),
                         "metaAnalysis_Comparisons_SuppFigure4_2024_named.png"),
       height = 3,
       width = 5.75,
       device = "png", dpi = 300)

```




### Supp. Fig. 9: Parallelization decreases runtime of invivoPKfit

Here I do a bit of benchmarking for the parallel-ized version of do_fit

```{r do_fit-benchmarking, eval=FALSE}


new_chemicals <- sample(unique(cvt %>% 
                                 filter(species %in% "rat") %>%
                                 pull(analyte_dtxsid)),
                       size = 4)

my_predata <- cvt %>%
  dplyr::filter(analyte_dtxsid %in% new_chemicals)

# Do each optimizer separately
my_pk_l <- pk(data = my_predata) +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = TRUE,
                      suppress.messages = FALSE) +
  settings_optimx(method = c("L-BFGS-B")) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  stat_error_model(error_group = vars(Chemical, Species))
my_pk_b <- pk(data = my_predata) +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = TRUE,
                      suppress.messages = FALSE) +
  settings_optimx(method = c("bobyqa")) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  stat_error_model(error_group = vars(Chemical, Species))
my_pk_l <- do_prefit(my_pk_l) # Then run again
my_pk_b <- do_prefit(my_pk_b)


# Set to one of the pre-fitted pk objects

single_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l), times = 3)
four_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 4), times = 3)
ten_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 10), times = 3)
fourteen_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 14), times = 3)

single_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b), times = 3)
four_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 4), times = 3)
ten_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 10), times = 3)
fourteen_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 14), times = 3)

# Choose the data group number below and then re-run...

four_DG_L <- bind_rows(summary(single_core_l),
                     summary(four_core_l),
                     summary(ten_core_l),
                     summary(fourteen_core_l))

four_DG_B <- bind_rows(summary(single_core_b),
                     summary(four_core_b),
                     summary(ten_core_b),
                     summary(fourteen_core_b))




new_chemicals <- sample(unique(cvt %>% 
                                 filter(species %in% "rat") %>%
                                 pull(analyte_dtxsid)),
                       size = 16)

my_predata <- cvt %>%
  dplyr::filter(analyte_dtxsid %in% new_chemicals)

# Do each optimizer separately
my_pk_l <- pk(data = my_predata) +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = TRUE,
                      suppress.messages = FALSE) +
  settings_optimx(method = c("L-BFGS-B")) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  stat_error_model(error_group = vars(Chemical, Species))
my_pk_b <- pk(data = my_predata) +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = TRUE,
                      suppress.messages = FALSE) +
  settings_optimx(method = c("bobyqa")) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  stat_error_model(error_group = vars(Chemical, Species))
my_pk_l <- do_prefit(my_pk_l) # Then run again
my_pk_b <- do_prefit(my_pk_b)


# Set to one of the pre-fitted pk objects

single_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l), times = 3)
four_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 4), times = 3)
ten_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 10), times = 3)
fourteen_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 14), times = 3)

single_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b), times = 3)
four_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 4), times = 3)
ten_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 10), times = 3)
fourteen_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 14), times = 3)


sixteen_DG_L <- bind_rows(summary(single_core_l),
                        summary(four_core_l),
                        summary(ten_core_l),
                        summary(fourteen_core_l)) # Done

sixteen_DG_B <- bind_rows(summary(single_core_b),
                        summary(four_core_b),
                        summary(ten_core_b),
                        summary(fourteen_core_b)) # Done

new_chemicals <- sample(unique(cvt %>% 
                                 filter(species %in% "rat") %>%
                                 pull(analyte_dtxsid)),
                       size = 32)

my_predata <- cvt %>%
  dplyr::filter(analyte_dtxsid %in% new_chemicals)

# Do each optimizer separately
my_pk_l <- pk(data = my_predata) +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = TRUE,
                      suppress.messages = FALSE) +
  settings_optimx(method = c("L-BFGS-B")) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  stat_error_model(error_group = vars(Chemical, Species))
my_pk_b <- pk(data = my_predata) +
  facet_data(vars(Chemical, Species)) +
  settings_preprocess(keep_data_original = TRUE,
                      suppress.messages = FALSE) +
  settings_optimx(method = c("bobyqa")) +
  scale_conc(dose_norm = TRUE, log10_trans = FALSE) +
  stat_error_model(error_group = vars(Chemical, Species))
my_pk_l <- do_prefit(my_pk_l) # Then run again
my_pk_b <- do_prefit(my_pk_b)


# Set to one of the pre-fitted pk objects

single_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l), times = 3)
four_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 4), times = 3)
ten_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 10), times = 3)
fourteen_core_l <- microbenchmark::microbenchmark(do_fit(my_pk_l, n_cores = 14), times = 3)

single_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b), times = 3)
four_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 4), times = 3)
ten_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 10), times = 3)
fourteen_core_b <- microbenchmark::microbenchmark(do_fit(my_pk_b, n_cores = 14), times = 3)


thirtytwo_DG_L <- bind_rows(summary(single_core_l),
                        summary(four_core_l),
                        summary(ten_core_l),
                        summary(fourteen_core_l)) 


thirtytwo_DG_B <- bind_rows(summary(single_core_b),
                        summary(four_core_b),
                        summary(ten_core_b),
                        summary(fourteen_core_b)) # Done


##
##
# After getting all of them
full_df <- bind_rows(
  four_DG_L %>% mutate(data_group_N = 4, method = "L-BFGS-B"),
  sixteen_DG_L %>% mutate(data_group_N = 16, method = "L-BFGS-B"),
  thirtytwo_DG_L %>% mutate(data_group_N = 32, method = "L-BFGS-B"),
  four_DG_B %>% mutate(data_group_N = 4, method = "bobyqa"),
  sixteen_DG_B %>% mutate(data_group_N = 16, method = "bobyqa"),
  thirtytwo_DG_B %>% mutate(data_group_N = 32, method = "bobyqa")
)

full_df <- full_df %>%
  mutate(N_cores = as.numeric(str_extract(expr, pattern = "[:digit:]+"))) %>%
  mutate(N_cores = ifelse(is.na(N_cores), 1, N_cores))

full_long <- full_df %>% 
         dplyr::select(expr, N_cores, data_group_N, method, min, median, max) %>%
         pivot_longer(cols = c(min, median, max)) %>%
  dplyr::select(-name)

df_long <- full_df %>% 
         dplyr::select(expr, N_cores, data_group_N, method, min, median, max) %>%
         pivot_longer(cols = c(min, median, max)) %>%
  dplyr::select(-name) %>% 
  group_by(N_cores, data_group_N, method) %>%
  summarize(avg_val = mean(value),
            sd_val = sd(value))



ggplot(full_long,
       aes(x = N_cores,
           y = value,
           color = paste(data_group_N))) +
  geom_point() +
  geom_line(data = df_long,
            aes(x = N_cores,
                y = avg_val)) +
  scale_x_continuous(breaks = c(0, 1, 4, 10, 14)) +
  facet_grid(rows = vars(method), scales = "free_y") +
  labs(x = "Number of Cores",
       y = "Runtime (seconds)",
       color = "Data Groups") +
  theme(panel.border = element_rect(color = "black", fill = NA, size = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        legend.key = element_rect(fill = "white"),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        strip.background = element_blank())




ggsave(paste0(Sys.getenv("FIG_DIR"),
              "Parallelization_Benchmarking_20240213.png"),
       width = 4.5,
       height = 4.5,
       units = "in")

```

### Supp. Fig. 10: Example plots for data fits

```{r sfig6-examples-of-fits, eval=FALSE}
pl <- plot(my_pk, use_scale_conc = TRUE, n_interp = 10)
names(pl) # Chemical Species observations observation_plot predicted predicted_plot final_plot

s6_plA <- pl %>% filter(Chemical %in% "DTXSID3031860") %>%
  pull(observation_plot) %>% .[[1]]
s6_plB_mouse <- pl %>% filter(Chemical %in% "DTXSID4020533",
                              Species %in% "mouse") %>% pull(final_plot) %>% .[[1]]
s6_plB_rat <- pl %>% filter(Chemical %in% "DTXSID4020533",
                              Species %in% "rat") %>% pull(final_plot) %>% .[[1]]
s6_plC <- pl %>% filter(Chemical %in% "DTXSID00216205") %>%
  pull(final_plot) %>% .[[1]]
s6_plD <- pl %>% filter(Chemical %in% "DTXSID8025337") %>%
  pull(final_plot) %>% .[[1]]

# Set colors palettes for each
# panel A : Oranges
panelA_cols <- brewer.pal(8, "Oranges")[3:8]
# panel B : Greens
panelB_cols <- brewer.pal(9, "Greens")[2:10]
# panel C : Blue (only 2 values) 
# panel D : Purple (6 values)
panelD_cols <- brewer.pal(9, "Purples")[4:9]

s6_plA <- s6_plA + 
  labs(title = "perfluorodecanoic acid") +
  scale_color_manual(values = panelA_cols, aesthetics = c("color", "fill")) +
  theme(text = element_text(size = 20),
        legend.position = "none",
        strip.background = element_rect(fill = "white"))

s6_plB_mouse <- s6_plB_mouse + 
  labs(title = "1,4-dioxane\nMouse") +
  scale_color_manual(values = panelB_cols[c(5,8)],
                     aesthetics = c("color", "fill")) +
  theme(text = element_text(size = 20),
        legend.position = "none",
        strip.background = element_rect(fill = "white"))

s6_plB_rat <- s6_plB_rat + 
  labs(title = "1,4-dioxane\nRat") +
  scale_color_manual(values = panelB_cols[c(1, 2, 3, 4, 5, 6,7, 8)],
                     aesthetics = c("color", "fill")) +
  theme(text = element_text(size = 20),
        legend.position = "none",
        strip.background = element_rect(fill = "white"))

s6_plC <- s6_plC +
  labs(title = "psoralen") +
  scale_color_manual(values = c("#6BAED6", "#08519C", "darkblue"),
                     aesthetics = c("color", "fill")) +
  theme(text = element_text(size = 20),
        legend.position = "none",
        strip.background = element_rect(fill = "white"))

s6_plD <- s6_plD +
  labs(title = "formamide") +
  scale_color_manual(values = panelD_cols,
                     aesthetics = c("color", "fill")) +
  theme(text = element_text(size = 20),
        legend.position = "none",
        strip.background = element_rect(fill = "white"))

# Put it all together
s6_plB <- plot_grid(s6_plB_mouse, s6_plB_rat,
            align = "h", axis = "bt",
           rel_widths = c(1.2,2))


s6_plCD <- plot_grid(s6_plC, s6_plD, labels = c("C", "D"), label_size = 24)


plot_grid(
  s6_plA,
  s6_plB,
  s6_plCD,
  align = "v",
  ncol = 1,
  rel_heights = c(1.25, 1.2, 1.25),
  labels = c("A", "B", ""),
  label_size = 24
)

# Am making this 2X the size I need it to be 
# so the points are a reasonable size when I scale it down
ggsave(paste0(Sys.getenv("FIG_DIR"),
              "ExampleFitsPlots_06.12.2024.png"),
       width = 13,
       height = 14,
       units = "in")

```


### NCA variation analysis
Here I decide to investigate data where fits were aborted and how many 
time-points occurred before non-compartmental t~max~, which essentially
asks whether there are enough detectable (above LOQ) data points to model absorption.
As a threshold for whether absorption can be modeled, I count those that have at least
more than one data point prior to the empirical t~max~. With at least three points
(including t~max~) we can reasonably begin to assess the absorption of a compound.


```{r more_analysis, eval=FALSE}


my_pk$prefit$fit_check %>% filter(fit_decision == "abort") %>%
  dplyr::select(model, Chemical) %>% distinct()

all_my_data %>%
  filter(Chemical == "DTXSID2021315")


# On average, how many time-points before tmax (empirical)?
my_nca %>% filter(param_name %in% "tmax") %>%
  dplyr::select(Chemical, Species, Route, Media, tmax.nca = param_value) %>%
  left_join(all_my_data) %>%
  filter(Route %in% "oral", Time < tmax.nca) %>%
  distinct(Chemical, Chemical_Name, Species, Route, Media, Detect, Time) %>%
  group_by(Chemical, Chemical_Name, Species, Route, Media, Detect) %>%
  count(name = "tp_before_tmax") %>%
  ungroup() %>% 
  filter(Detect == TRUE) %>%
  dplyr::select(!Detect) %>%
  arrange(tp_before_tmax) %>%
  count(tp_before_tmax > 1)
  
```

Here I introduce the notion whether the data is variable compared across time.

```{r PredictionVariability_overtime, eval=FALSE}
my_residuals %>%
  filter(exclude == FALSE) %>%
  inner_join(winmodel) %>%
  inner_join(my_tkstats %>%
              dplyr::select(Chemical, Species,
                            Route, Media,
                            tmax = tmax.tkstats) %>%
              filter(!is.na(tmax))) %>%
  group_by(Chemical,
           Species,
           Route,
           Media,
           Dose) %>%
  mutate(
         normTime = ifelse(
           Route == "iv",
           1 + Time/max(Time),
           ifelse(
             Time > tmax,
             ((Time - tmax)/max(Time)) + 1,
             0.5 + Time/(2*tmax)
           )
         )) %>%
  distinct() %>%
  filter(Detect %in% TRUE) -> my_residuals2
my_residuals2 %>%
  # filter(Route == "oral") %>% View()
  ggplot(aes(
    x = normTime,
    y = Residuals
  )) +
  geom_point(alpha = 0.2, size = 0.5) +
  geom_point(data = filter(my_residuals2,
                           Chemical %in% "DTXSID4020533",
                           Species %in% "rat"),
             color = "orange2", size = 0.5) +
  geom_point(data = filter(my_residuals2,
                           Chemical %in% "DTXSID8031865",
                           Species %in% "rat"),
             color = "magenta4", size = 0.5) +
  geom_point(data = filter(my_residuals2,
                           Chemical %in% "DTXSID8025337",
                           Species %in% "rat"),
             color = "green2", size = 0.5) +
  geom_vline(xintercept = 1, color = "blue", linetype = "dashed") +
  geom_vline(xintercept = 2, color = "green4", linetype = "dashed") +
  facet_grid(cols = vars(Route),
             # rows = vars(model),
             scales = "free_x") +
  labs(x = "ADME-Normalized Time",
       y = "Winning Model Residuals") +
  theme(aspect.ratio = 1,
        panel.border = element_rect(color = "black", fill = NA, size = 1.5),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "grey90", linewidth = 0.5),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text.x = element_blank())

ggsave(paste0(Sys.getenv("FIG_DIR"),
              "ADME_NormalizedTime-WinModelResiduals_onlyDetects_Highlighted_2023-07-19.png"),
       height = 4,
       width = 6,
       units = "in")
```


I try to find the connections between functions in _invivoPKfit_ to best understand
and represent the structure of the package.

```{r function_connections, eval=FALSE}
fw <- mvbutils::foodweb(where = asNamespace("invivoPKfit"),
                        border = TRUE, cex = 0.6, lwd = 1.5)
fun_mat <- fw$funmat

mvbutils::foodweb(where = asNamespace("invivoPKfit"),
                  prune = "calc_auc",
                  # descendants = FALSE,
                  # ancestors = FALSE,
                  border = TRUE, cex = 1, lwd = 1.5)

# Predict dependents: rmse, residuals, rsq, calc_auc, fold_errors, plot
# Coef dependents: calc_auc, predict, get_tkstats, summary,log_Lik, coef_sd

# list of all functions and methods
fm <- ls(asNamespace("invivoPKfit"))
fm <- fm[!grepl(".default", x = fm)]

pdf(file = paste0(Sys.getenv("FIG_DIR"),
              "NonDefaultFunction_Connections.pdf"),
    height = 8, width = 8)
for (i in fm) {
  mvbutils::foodweb(where = asNamespace("invivoPKfit"),
                  prune = i,
                  # descendants = FALSE,
                  # ancestors = FALSE,
                  border = TRUE, cex = 1, lwd = 1.5)
}
dev.off()



```



## Other Plots

### Plotting ALL fits for Dose-normalized Joint fits (L-BFGS-B)

Here is the code used to generate the CvT data and _invivoPKfit_ fits
for each chemical, species data group.

```{r plotting_all_Fits, eval=FALSE}
### Plotting for all (2.5MB file)
pl <- plot(my_pk, n_interp = 12, use_scale_conc = TRUE)
pdf(file = paste0(Sys.getenv("FIG_DIR"),
              "Transformed_Joint_AllFits_Final_2024_05_16.pdf"),
    height = 6, width = 10)
for (i in 1:nrow(pl)) {
  print(pl$final_plot[[i]])
}
dev.off()

# From my new SQL pull
pl <- plot(my_pk, n_interp = 12, use_scale_conc = FALSE, best_fit = TRUE)
pdf(file = paste0(Sys.getenv("FIG_DIR"),
              "Joint_bobyqa_AllFits_Final_20240514.pdf"),
    height = 10, width = 10)
for (i in 1:nrow(pl)) {
  print(pl$final_plot[[i]])
}
dev.off()

```

It is also possible to plot only one plot

```{r Single-Plot, eval=FALSE}
pl <- plot(my_pk, n_interp = 10, use_scale_conc = FALSE)
pl %>%
  filter(Chemical %in% "DTXSID5020029") %>%
  pull(final_plot) %>% .[[1]]

```


### Figure 2: Example Fits to Explain Joint vs Pooled Models


```{r Explain-Heirarchical-Model, eval=FALSE}
# Note that the data will run one "Series" of time point at a time
my_1comp <- function(t, F_V, kelim, kabs, sd = 0) {
  sd + (F_V * (kabs * (exp(-kelim * t) - exp(-kabs * t))) / (kabs - kelim))
}

my_cdata <- data.frame(
  Reference = rep(rep(c("X", "O"), each = 3), 6),
  Time = rep(c(0, 2, 4, 6, 8, 12), each = 6),
  Concentration = c(
    4, 5, 6.5,
    4.5, 5, 6,
    8, 9, 9.5,
    7.5, 8, 8.5,
    3, 4.5, 6,
    3.5, 4, 5,
    2, 2.5, 4,
    1, 1.5, 2.25,
    0.4, 1, 2,
    0.4, 0.8, 1,
    0.2, 0.5, 1,
    0.25, 0.4, 0.5
  ) 
)


pl_pool <- ggplot() +
  geom_point(data = my_cdata,
             mapping = aes(
               x = Time,
               y = Concentration,
               color = Reference
             ),
             position = position_dodge(width = 0.4),
             size = 2) +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8),
    linewidth = 1) +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8, sd = 1),
    linewidth = 0.5, linetype = "dashed") +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8, sd = -1),
    linewidth = 0.5, linetype = "dashed") +
  scale_y_continuous(breaks = scales::pretty_breaks(10)) +
  scale_x_continuous(breaks = scales::pretty_breaks(13)) +
  scale_color_manual(values = c("black", "black")) +
  theme_classic() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_text(size = 12, face = "bold"),
        axis.line = element_line(linewidth = 1, lineend = "square"),
        legend.position = "none")
ggsave(paste0(Sys.getenv("FIG_DIR"), "PooledExampleFigure.png"),
       units = "in",
       height = 4,
       width = 5,
       device = "png",
       dpi = 300)

# Change shape(s) from circles
pl_joint <- ggplot() +
  geom_point(data = my_cdata,
             mapping = aes(
               x = Time,
               y = Concentration,
               color = Reference,
               shape = Reference
             ),
             position = position_dodge(width = 0.4),
             size = 2) +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8),
    linewidth = 1) +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8, sd = 1.3),
    linewidth = 0.6, linetype = "dashed", color = "green4") +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8, sd = -1.3),
    linewidth = 0.6, linetype = "dashed", color = "green4") +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8, sd = 0.7),
    linewidth = 0.6, linetype = "dashed", color = "magenta3") +
  stat_function(
    fun = my_1comp,
    args = list(F_V = 20, kelim = 0.6, kabs = 0.8, sd = -0.7),
    linewidth = 0.6, linetype = "dashed", color = "magenta3") +
  scale_y_continuous(breaks = scales::pretty_breaks(10)) +
  scale_x_continuous(breaks = scales::pretty_breaks(13)) +
  scale_color_manual(values = c("magenta3", "green4")) +
  scale_shape_manual(values = c(15, 17)) +
  theme_classic() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_text(size = 12, face = "bold"),
        axis.line = element_line(linewidth = 1, lineend = "square"),
        axis.title.y = element_blank(),
        legend.position = "none")

pl_joint
ggsave(paste0(Sys.getenv("FIG_DIR"), "JointExampleFigure.png"),
       units = "in",
       height = 4,
       width = 5,
       device = "png",
       dpi = 300)


plot_grid(pl_pool, pl_joint,
          align = "h", axis = "bt")

ggsave(filename = paste0(Sys.getenv("FIG_DIR"),
                         "Pooled_Joint_ExampleFigure.png"),
       units = "in",
       height = 3.4,
       width = 6.5,
       device = "png",
       dpi = 300)

ggplot(data.frame(point_size = seq(0.2, 3, by = 0.2)),
       aes(x = as.factor(point_size), size = point_size)) +
  geom_point(y = 0) +
  scale_y_continuous(limits = c(-1, 1)) +
  theme_bw() +
  theme(legend.position = "none")

ggsave(paste0(Sys.getenv("FIG_DIR"), "Point_Reference_3x5.png"),
       units = "in",
       height = 3,
       width = 5,
       device = "png",
       dpi = 300)
```

